{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.13 创建数据处理管道\n",
    "\"\"\"问题\n",
    "你想以数据管道(类似Unix管道)的方式迭代处理数据。 比如，你有个大量的数据需要处理，但是不\n",
    "能将它们一次性放入内存中。\n",
    "\n",
    "解决方案\n",
    "生成器函数是一个实现管道机制的好办法。 为了演示，假定你要处理一个非常大的日志文件目录：\n",
    "\n",
    "foo/\n",
    "    access-log-012007.gz\n",
    "    access-log-022007.gz\n",
    "    access-log-032007.gz\n",
    "    ...\n",
    "    access-log-012008\n",
    "bar/\n",
    "    access-log-092007.bz2\n",
    "    ...\n",
    "    access-log-022008\n",
    "假设每个日志文件包含这样的数据：\n",
    "\n",
    "124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] \"GET /robots.txt ...\" 200 71\n",
    "210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] \"GET /ply/ ...\" 200 11875\n",
    "210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] \"GET /favicon.ico ...\" 404 369\n",
    "61.135.216.105 - - [10/Jul/2012:00:20:04 -0500] \"GET /blog/atom.xml ...\" 304 -\n",
    "...\n",
    "为了处理这些文件，你可以定义一个由多个执行特定任务独立任务的简单生成器函数组成的容器。就\n",
    "像这样：\"\"\"\n",
    "import os\n",
    "import fnmatch\n",
    "import gzip\n",
    "import bz2\n",
    "import re\n",
    "\n",
    "def gen_find(filepat, top):\n",
    "    '''Find all filenames in diretory tree that match a shell wildcard pattern'''\n",
    "    for path, dirlist, filelist in os.walk(top):\n",
    "        for name in fnmatch.filter(filelist, filepat):\n",
    "            yield os.path.join(path, name)\n",
    "            \n",
    "def gen_opener(filenames):\n",
    "    '''Open a sequence of filenames one at a time producing a file object.\n",
    "    The file is closed immediately when proceeding to the next iteration.\n",
    "    '''\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.gz'):\n",
    "            f = gzip.open(filename, 'rt')\n",
    "        elif filename.endswith('.bz2'):\n",
    "            f = bz2.open(filename, 'rt')\n",
    "        else:\n",
    "            f = open(filename, 'rt')\n",
    "        yield f\n",
    "        f.close()\n",
    "        \n",
    "def gen_concatenate(iterators):\n",
    "    '''\n",
    "    Chain a sequence of iterators together into a single sequence.\n",
    "    '''\n",
    "    for it in iterators:\n",
    "        yield from it\n",
    "        \n",
    "def gen_grep(pattern, lines):\n",
    "    '''\n",
    "    Look for a regex pattern in a sequence of lines\n",
    "    '''\n",
    "    pat = re.compile(pattern)\n",
    "    for line in lines:\n",
    "        if pat.search(line):\n",
    "            yield line\n",
    "\"\"\"现在你可以很容易的将这些函数连起来创建一个处理管道。 比如，为了查找包含单词python的所\n",
    "有日志行，你可以这样做：\"\"\"\n",
    "lognames = gen_find('access-log*', 'www')\n",
    "files = gen_opener(lognames)\n",
    "lines = gen_concatenate(files)\n",
    "pylines = gen_grep('(?i)python', lines)\n",
    "for line in pylines:\n",
    "    print(line)\n",
    "\"\"\"如果将来的时候你想扩展管道，你甚至可以在生成器表达式中包装数据。 比如，下面这个版本计\n",
    "算出传输的字节数并计算其总和。\"\"\"\n",
    "lognames = gen_find('access-log*', 'www')\n",
    "files = gen_opener(lognames)\n",
    "lines = gen_concatenate(files)\n",
    "pylines = gen_grep('(?i)python', lines)\n",
    "bytecolumn = (line.rsplit(None,1)[1] for line in pylines)\n",
    "bytes = (int(x) for x in bytecolumn if x != '-')\n",
    "print('Total', sum(bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"讨论\n",
    "以管道方式处理数据可以用来解决各类其他问题，包括解析，读取实时数据，定时轮询等。\n",
    "\n",
    "为了理解上述代码，重点是要明白 yield 语句作为数据的生产者而 for 循环语句作为数据的消\n",
    "费者。 当这些生成器被连在一起后，每个 yield 会将一个单独的数据元素传递给迭代处理管道的\n",
    "下一阶段。 在例子最后部分， sum() 函数是最终的程序驱动者，每次从生成器管道中提取出一个\n",
    "元素。\n",
    "\n",
    "这种方式一个非常好的特点是每个生成器函数很小并且都是独立的。这样的话就很容易编写和维护它\n",
    "们了。 很多时候，这些函数如果比较通用的话可以在其他场景重复使用。 并且最终将这些组件组合\n",
    "起来的代码看上去非常简单，也很容易理解。\n",
    "\n",
    "使用这种方式的内存效率也不得不提。上述代码即便是在一个超大型文件目录中也能工作的很好。 \n",
    "事实上，由于使用了迭代方式处理，代码运行过程中只需要很小很小的内存。\n",
    "\n",
    "在调用 gen_concatenate() 函数的时候你可能会有些不太明白。 这个函数的目的是将输入序列拼\n",
    "接成一个很长的行序列。 itertools.chain() 函数同样有类似的功能，但是它需要将所有可迭代对\n",
    "象最为参数传入。 在上面这个例子中，你可能会写类似这样的语句 lines = \n",
    "itertools.chain(*files) ， 使得 gen_opener() 生成器能被全部消费掉。 但由于 gen_opener() \n",
    "生成器每次生成一个打开过的文件， 等到下一个迭代步骤时文件就关闭了，因此 chain() 在这里不\n",
    "能这样使用。 上面的方案可以避免这种情况。\n",
    "\n",
    "gen_concatenate() 函数中出现过 yield from 语句，它将 yield 操作代理到父生成器上去。 语句\n",
    "yield from it 简单的返回生成器 it 所产生的所有值。 关于这个我们在4.14小节会有更进一步的\n",
    "描述。\n",
    "\n",
    "最后还有一点需要注意的是，管道方式并不是万能的。 有时候你想立即处理所有数据。 然而，即\n",
    "便是这种情况，使用生成器管道也可以将这类问题从逻辑上变为工作流的处理方式。\n",
    "\n",
    "David Beazley 在他的 Generator Tricks for Systems Programmers 教程中对于这种技术有非\n",
    "常深入的讲解。可以参考这个教程获取更多的信息。\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
