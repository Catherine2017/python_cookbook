{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60632 23\n",
      "60647 1\n"
     ]
    }
   ],
   "source": [
    "# 6.4 增量式解析大型XML文件\n",
    "\"\"\"问题\n",
    "你想使用尽可能少的内存从一个超大的XML文档中提取数据。\n",
    "\n",
    "解决方案\n",
    "任何时候只要你遇到增量式的数据处理时，第一时间就应该想到迭代器和生成器。 下面是一个很简单的函数，只使用很少的内存就能增量式的处理一个大型XML文件：\"\"\"\n",
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # skip the root element\n",
    "    next(doc)\n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    \n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem\n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "\"\"\"为了测试这个函数，你需要先有一个大型的XML文件。 通常你可以在政府网站或公共数据网站上找到这样的文件。 例如，你可以下载XML格式的芝加哥城市道路坑洼数据库。 在写这本书的时候，下载文件已经包含超过100,000行数据，编码格式类似于下面这样：\"\"\"\n",
    "from xml.etree.ElementTree import parse\n",
    "from collections import Counter\n",
    "potholes_by_zip = Counter()\n",
    "doc = parse('potholes.xml')\n",
    "for pothole in doc.iterfind('row/row'):\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60632 23\n",
      "60647 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"这个脚本唯一的问题是它会先将整个XML文件加载到内存中然后解析。 在我的机器上，为了运行这个程序需要用到450MB左右的内存空间。 如果使用如下代码，程序只需要修改一点点：\"\"\"\n",
    "from collections import Counter\n",
    "potholes_by_zip = Counter()\n",
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'response' at 0x00000296356507C8>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"讨论\n",
    "这一节的技术会依赖 ElementTree 模块中的两个核心功能。 第一，iterparse() 方法允许对XML文档进行增量操作。 使用时，你需要提供文件名和一个包含下面一种或多种类型的事件列表： start , end, start-ns 和 end-ns 。 由 iterparse() 创建的迭代器会产生形如 (event, elem) 的元组， 其中 event 是上述事件列表中的某一个，而 elem 是相应的XML元素。例如：\"\"\"\n",
    "data = iterparse('potholes.xml', ('start', 'end'))\n",
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'row' at 0x00000296354A2B38>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'row' at 0x00000296354A2D18>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('start', <Element 'creation_date' at 0x00000296354A2DB8>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('end', <Element 'creation_date' at 0x00000296354A2DB8>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'row' at 0x000002963592DA98>\n",
      "<Element 'row' at 0x000002963593E0E8>\n",
      "<Element 'row' at 0x000002963593E6D8>\n",
      "<Element 'row' at 0x000002963593ECC8>\n",
      "<Element 'row' at 0x0000029635942318>\n",
      "<Element 'row' at 0x0000029635942908>\n",
      "<Element 'row' at 0x0000029635942EF8>\n",
      "<Element 'row' at 0x0000029635946548>\n",
      "<Element 'row' at 0x0000029635946B38>\n",
      "<Element 'row' at 0x0000029635948188>\n",
      "<Element 'row' at 0x0000029635948778>\n",
      "<Element 'row' at 0x0000029635948D68>\n",
      "<Element 'row' at 0x000002963594B3B8>\n",
      "<Element 'row' at 0x000002963594B9A8>\n",
      "<Element 'row' at 0x000002963594BF98>\n",
      "<Element 'row' at 0x00000296359915E8>\n",
      "<Element 'row' at 0x000002963594BF48>\n",
      "<Element 'row' at 0x000002963594B958>\n",
      "<Element 'row' at 0x000002963594B318>\n",
      "<Element 'row' at 0x000002963592DCC8>\n",
      "<Element 'row' at 0x0000029635991EA8>\n",
      "<Element 'row' at 0x00000296359424F8>\n",
      "<Element 'row' at 0x0000029635942AE8>\n",
      "<Element 'row' at 0x000002963593EF48>\n"
     ]
    }
   ],
   "source": [
    "data = parse_and_remove('potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    print(pothole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"start 事件在某个元素第一次被创建并且还没有被插入其他数据(如子元素)时被创建。 而 end 事件在某个元素已经完成时被创建。 尽管没有在例子中演示， start-ns 和 end-ns 事件被用来处理XML文档命名空间的声明。\n",
    "\n",
    "这本节例子中， start 和 end 事件被用来管理元素和标签栈。 栈代表了文档被解析时的层次结构， 还被用来判断某个元素是否匹配传给函数 parse_and_remove() 的路径。 如果匹配，就利用 yield 语句向调用者返回这个元素。\n",
    "\n",
    "在 yield 之后的下面这个语句才是使得程序占用极少内存的ElementTree的核心特性：\n",
    "\n",
    "elem_stack[-2].remove(elem)\n",
    "这个语句使得之前由 yield 产生的元素从它的父节点中删除掉。 假设已经没有其它的地方引用这个元素了，那么这个元素就被销毁并回收内存。\n",
    "\n",
    "对节点的迭代式解析和删除的最终效果就是一个在文档上高效的增量式清扫过程。 文档树结构从始自终没被完整的创建过。尽管如此，还是能通过上述简单的方式来处理这个XML数据。\n",
    "\n",
    "这种方案的主要缺陷就是它的运行性能了。 我自己测试的结果是，读取整个文档到内存中的版本的运行速度差不多是增量式处理版本的两倍快。 但是它却使用了超过后者60倍的内存。 因此，如果你更关心内存使用量的话，那么增量式的版本完胜。\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
